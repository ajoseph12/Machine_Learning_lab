{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.ensemble import BalanceCascade, EasyEnsemble\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb \n",
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours, TomekLinks\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read dataset\n",
    "\n",
    "df_x_train = pd.read_csv('dataset/train.csv', header= None)\n",
    "df_y_train = pd.read_csv('dataset/train_labels.csv', header= None)\n",
    "df_y_train.columns = ['label']\n",
    "df_train = pd.concat((df_x_train,df_y_train), axis = 1) # concatenate X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1280665.0</td>\n",
       "      <td>5735.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336463.0</td>\n",
       "      <td>5977.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>899868.0</td>\n",
       "      <td>5651.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2177924.0</td>\n",
       "      <td>5691.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.6</td>\n",
       "      <td>89.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>259.74</td>\n",
       "      <td>89.6</td>\n",
       "      <td>259.74</td>\n",
       "      <td>259.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280665.0</td>\n",
       "      <td>5735.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1      2    3    4      5    6    7    8    9  ...      44  \\\n",
       "0  1280665.0  5735.0  121.0  1.0  0.0  978.0  5.0  4.0  0.0  1.0  ...     0.0   \n",
       "1   336463.0  5977.0   67.0  1.0  0.0  978.0  5.0  3.0  0.0  1.0  ...     0.0   \n",
       "2   899868.0  5651.0   67.0  1.0  0.0  978.0  5.0  4.0  0.0  1.0  ...     0.0   \n",
       "3  2177924.0  5691.0   16.0  0.0  0.0  978.0  0.0  2.0  1.0  0.0  ...    89.6   \n",
       "4  1280665.0  5735.0  121.0  1.0  0.0  978.0  5.0  4.0  0.0  1.0  ...     0.0   \n",
       "\n",
       "     45   46   47    48      49    50      51      52  label  \n",
       "0   0.0  0.0  0.0  2.99    0.00   0.0    0.00    0.00    0.0  \n",
       "1   0.0  0.0  0.0  0.00   78.00   0.0   78.00   78.00    0.0  \n",
       "2   0.0  0.0  0.0  0.00    0.00   0.0    0.00    0.00    0.0  \n",
       "3  89.6  0.0  0.0  0.00  259.74  89.6  259.74  259.74    0.0  \n",
       "4   0.0  0.0  0.0  0.00    0.00   0.0    0.00    0.00    0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.153017e+06</td>\n",
       "      <td>5789.592100</td>\n",
       "      <td>66.060790</td>\n",
       "      <td>0.527930</td>\n",
       "      <td>0.064770</td>\n",
       "      <td>950.622050</td>\n",
       "      <td>2.91140</td>\n",
       "      <td>2.935490</td>\n",
       "      <td>0.435090</td>\n",
       "      <td>0.585130</td>\n",
       "      <td>...</td>\n",
       "      <td>53.999384</td>\n",
       "      <td>48.141110</td>\n",
       "      <td>28.247964</td>\n",
       "      <td>41.570204</td>\n",
       "      <td>82.746682</td>\n",
       "      <td>80.435257</td>\n",
       "      <td>51.255593</td>\n",
       "      <td>67.784037</td>\n",
       "      <td>80.320324</td>\n",
       "      <td>0.002130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.408450e+05</td>\n",
       "      <td>998.402186</td>\n",
       "      <td>56.379468</td>\n",
       "      <td>0.499222</td>\n",
       "      <td>0.246121</td>\n",
       "      <td>113.129153</td>\n",
       "      <td>2.58682</td>\n",
       "      <td>0.943153</td>\n",
       "      <td>0.495771</td>\n",
       "      <td>0.492702</td>\n",
       "      <td>...</td>\n",
       "      <td>1218.064010</td>\n",
       "      <td>1210.159503</td>\n",
       "      <td>1138.933516</td>\n",
       "      <td>1192.381318</td>\n",
       "      <td>1343.725633</td>\n",
       "      <td>1226.869895</td>\n",
       "      <td>1211.007185</td>\n",
       "      <td>1216.991705</td>\n",
       "      <td>1231.975149</td>\n",
       "      <td>0.046103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.200000e+01</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.790780e+05</td>\n",
       "      <td>5411.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>978.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.060490e+06</td>\n",
       "      <td>5735.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>978.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.003550e+06</td>\n",
       "      <td>5968.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>978.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.386839e+06</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>203038.000000</td>\n",
       "      <td>203038.000000</td>\n",
       "      <td>203038.000000</td>\n",
       "      <td>203038.000000</td>\n",
       "      <td>203038.000000</td>\n",
       "      <td>203038.000000</td>\n",
       "      <td>203038.000000</td>\n",
       "      <td>203038.000000</td>\n",
       "      <td>203038.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1              2              3  \\\n",
       "count  1.000000e+05  100000.000000  100000.000000  100000.000000   \n",
       "mean   1.153017e+06    5789.592100      66.060790       0.527930   \n",
       "std    7.408450e+05     998.402186      56.379468       0.499222   \n",
       "min    6.200000e+01     742.000000       0.000000       0.000000   \n",
       "25%    4.790780e+05    5411.000000      16.000000       0.000000   \n",
       "50%    1.060490e+06    5735.000000      67.000000       1.000000   \n",
       "75%    2.003550e+06    5968.000000      95.000000       1.000000   \n",
       "max    2.386839e+06    9999.000000     224.000000       1.000000   \n",
       "\n",
       "                   4              5             6              7  \\\n",
       "count  100000.000000  100000.000000  100000.00000  100000.000000   \n",
       "mean        0.064770     950.622050       2.91140       2.935490   \n",
       "std         0.246121     113.129153       2.58682       0.943153   \n",
       "min         0.000000      -1.000000       0.00000       0.000000   \n",
       "25%         0.000000     978.000000       0.00000       2.000000   \n",
       "50%         0.000000     978.000000       5.00000       3.000000   \n",
       "75%         0.000000     978.000000       5.00000       4.000000   \n",
       "max         1.000000     986.000000       9.00000       5.000000   \n",
       "\n",
       "                   8              9      ...                   44  \\\n",
       "count  100000.000000  100000.000000      ...        100000.000000   \n",
       "mean        0.435090       0.585130      ...            53.999384   \n",
       "std         0.495771       0.492702      ...          1218.064010   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%         0.000000       0.000000      ...             0.000000   \n",
       "50%         0.000000       1.000000      ...             0.000000   \n",
       "75%         1.000000       1.000000      ...             0.000000   \n",
       "max         1.000000       1.000000      ...        203038.000000   \n",
       "\n",
       "                  45             46             47             48  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean       48.141110      28.247964      41.570204      82.746682   \n",
       "std      1210.159503    1138.933516    1192.381318    1343.725633   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.010000   \n",
       "max    203038.000000  203038.000000  203038.000000  203038.000000   \n",
       "\n",
       "                  49             50             51             52  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean       80.435257      51.255593      67.784037      80.320324   \n",
       "std      1226.869895    1211.007185    1216.991705    1231.975149   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%        21.300000       0.000000       7.000000      18.200000   \n",
       "max    203038.000000  203038.000000  203038.000000  203038.000000   \n",
       "\n",
       "               label  \n",
       "count  100000.000000  \n",
       "mean        0.002130  \n",
       "std         0.046103  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Treatement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## first 21 elements are categories and remaining floats\n",
    "for i in range(21):\n",
    "    df_train[i] = df_train[i].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nan values = 0\n",
      "Number of attributes with zero variance = 0\n",
      "Number of attributes with high variance = 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Everything seems just fine, except for column 0 \n",
    "\"\"\"\n",
    "## Check for NaNs\n",
    "temp_ls = df_train.isnull().any().tolist()\n",
    "print(\"Number of Nan values = {}\".format(sum(temp_ls)))\n",
    "\n",
    "## Check for zero variance \n",
    "zero_var = 0\n",
    "for i in range(53):\n",
    "    if len(df_train[i].value_counts()) == 1:\n",
    "        zero_var += 1\n",
    "print(\"Number of attributes with zero variance = {}\".format(zero_var))\n",
    "\n",
    "## Check of high variation \n",
    "high_var = 0\n",
    "temp_ls = list()\n",
    "for i in range(21): # only first 21 elements are categorical\n",
    "    if len(df_train[i].value_counts()) >= df_train.shape[0]/3:\n",
    "        temp_ls.append(i)\n",
    "        high_var += 1\n",
    "print(\"Number of attributes with high variance = {}\".format(high_var))\n",
    "\n",
    "df_train.drop(temp_ls, axis = 1, inplace = True)# drop columns in temp_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        category\n",
       "2        category\n",
       "3        category\n",
       "4        category\n",
       "5        category\n",
       "6        category\n",
       "7        category\n",
       "8        category\n",
       "9        category\n",
       "10       category\n",
       "11       category\n",
       "12       category\n",
       "13       category\n",
       "14       category\n",
       "15       category\n",
       "16       category\n",
       "17       category\n",
       "18       category\n",
       "19       category\n",
       "20       category\n",
       "21        float64\n",
       "22        float64\n",
       "23        float64\n",
       "24        float64\n",
       "25        float64\n",
       "26        float64\n",
       "27        float64\n",
       "28        float64\n",
       "29        float64\n",
       "30        float64\n",
       "31        float64\n",
       "32        float64\n",
       "33        float64\n",
       "34        float64\n",
       "35        float64\n",
       "36        float64\n",
       "37        float64\n",
       "38        float64\n",
       "39        float64\n",
       "40        float64\n",
       "41        float64\n",
       "42        float64\n",
       "43        float64\n",
       "44        float64\n",
       "45        float64\n",
       "46        float64\n",
       "47        float64\n",
       "48        float64\n",
       "49        float64\n",
       "50        float64\n",
       "51        float64\n",
       "52        float64\n",
       "label     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    99787\n",
       "1.0      213\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 0.2% are fraudulent data\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "## Normalizing \n",
    "x = df_train.values[:,20:-1] #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "## Delete existing numerical columns and replacing with normalised version\n",
    "col_name = [i for i in range(21, 53)]\n",
    "df_temp = pd.DataFrame(x_scaled, columns= col_name)\n",
    "df_train.drop(col_name, axis = 1, inplace = True)\n",
    "df_train = df_train.merge(df_temp,left_index=True, right_index=True)\n",
    "\n",
    "## Adding label to end of dataframe\n",
    "temp_ls = df_train['label'].tolist()\n",
    "df_train.drop('label', axis = 1, inplace = True)\n",
    "df_train['label'] = temp_ls\n",
    "df_train['label'] = df_train['label'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAElCAYAAACMItXlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2e9e7908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Finding correlated features\n",
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "corr = df_train.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Delete highly correlated terms (corr > 0.98)\n",
    "temp_ls = list()\n",
    "for i in corr.columns:\n",
    "    for j in range(i,len(corr.columns)+21):\n",
    "        if corr[i][j] > 0.98 and i != j: temp_ls.append((i,j))\n",
    "\n",
    "temp_ls = [j for(i,j) in temp_ls]\n",
    "df_train.drop(set(temp_ls), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get list of binary attributes \n",
    "temp_ls = list()\n",
    "for i in range(1,21):\n",
    "    temp = len(df_train[i].value_counts())\n",
    "    if temp <= 2: temp_ls.append(i)\n",
    "temp_ls.append('label')\n",
    "\n",
    "## Converting df to one-hot representation\n",
    "cols_oh = [i  for i in range(1,21) if i not in temp_ls]\n",
    "df_train_oh = pd.get_dummies(df_train, columns = cols_oh, sparse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "X = df_train.drop('label', axis = 1)\n",
    "X = X.as_matrix()\n",
    "Y = df_train['label'].as_matrix()\n",
    "Y = Y.astype('int')\n",
    "\n",
    "## Train - Test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Models - Weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I would test some SOTA machine learning models like, logistic regression, SVMs, decision trees, Random forest, Adaboost etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Non-weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19955\n",
      "        1.0       0.67      0.04      0.08        45\n",
      "\n",
      "avg / total       1.00      1.00      1.00     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(class_weight= 'balanced')\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.97      0.98     19955\n",
      "        1.0       0.02      0.29      0.04        45\n",
      "\n",
      "avg / total       1.00      0.97      0.98     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19339   616]\n",
      " [   32    13]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees - Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(class_weight = 'balanced')\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19955\n",
      "        1.0       0.12      0.22      0.15        45\n",
      "\n",
      "avg / total       1.00      0.99      1.00     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19880    75]\n",
      " [   35    10]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100], 'max_features': ['auto'], 'criterion': ['entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_base = RandomForestClassifier()\n",
    "grid  = {'n_estimators' :[100],\n",
    "         'max_features' : ['auto'],\n",
    "         'criterion' : ['entropy']}\n",
    "clf = GridSearchCV(clf_base, grid)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00     19955\n",
      "        1.0       1.00      0.09      0.16        45\n",
      "\n",
      "avg / total       1.00      1.00      1.00     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19955     0]\n",
      " [   41     4]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble - Logistic Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ens = EasyEnsemble(n_subsets= 25)\n",
    "X_train_ee, Y_train_ee = ens.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_probs_lr = np.zeros((20000,2))\n",
    "for idx in range(len(Y_train_ee)): \n",
    "    clf_lr = LogisticRegression()\n",
    "    grid  = {'C' : 10.0 ** np.arange(-2,3),\n",
    "             'penalty' : ['l2','l1']}\n",
    "    cv = KFold(n_splits = 3, shuffle = True, random_state=0)\n",
    "    clf_lr_boost = GridSearchCV(clf_lr, grid, cv = cv)\n",
    "    clf_lr_boost.fit(X_train_ee[idx], Y_train_ee[idx])\n",
    "    y_pred_probs_lr += clf_lr_boost.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90     19955\n",
      "          1       0.01      0.89      0.02        45\n",
      "\n",
      "avg / total       1.00      0.82      0.90     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, np.argmax(y_pred_probs_lr, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16308  3647]\n",
      " [    5    40]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, np.argmax(y_pred_probs_lr, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble - RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_probs_rf = np.zeros((20000,2))\n",
    "for idx in range(len(Y_train_ee)): \n",
    "    clf_base = RandomForestClassifier()\n",
    "    grid  = {'n_estimators' :[100],\n",
    "             'max_features' : ['auto'],\n",
    "             'criterion' : ['entropy']}\n",
    "    #cv = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "    clf_rf_boost = GridSearchCV(clf_base, grid)\n",
    "    clf_rf_boost.fit(X_train_ee[idx], Y_train_ee[idx])\n",
    "    y_pred_probs_rf += clf_rf_boost.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92     19955\n",
      "          1       0.01      0.91      0.03        45\n",
      "\n",
      "avg / total       1.00      0.85      0.92     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, np.argmax(y_pred_probs_rf, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17039  2916]\n",
      " [    4    41]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, np.argmax(y_pred_probs_rf, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble - ADAboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_probs_ada = np.zeros((20000,2))\n",
    "for idx in range(len(Y_train_ee)): \n",
    "    clf_ada = AdaBoostClassifier()\n",
    "    clf_ada.fit(X_train_ee[idx], Y_train_ee[idx])\n",
    "    y_pred_probs_ada += clf_ada.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92     19955\n",
      "          1       0.01      0.93      0.03        45\n",
      "\n",
      "avg / total       1.00      0.85      0.92     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, np.argmax(y_pred_probs_ada, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17049  2906]\n",
      " [    3    42]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, np.argmax(y_pred_probs_ada, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble - XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_probs_xg = np.zeros((20000,2))\n",
    "for idx in range(len(Y_train_ee)): \n",
    "    clf_xgb = xgb.XGBClassifier()\n",
    "\n",
    "    clf_xgb.fit(X_train_ee[idx], Y_train_ee[idx])\n",
    "    y_pred_probs_xg += clf_xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.93     19955\n",
      "          1       0.01      0.93      0.03        45\n",
      "\n",
      "avg / total       1.00      0.86      0.92     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, np.argmax(y_pred_probs_xg, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17182  2773]\n",
      " [    3    42]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, np.argmax(y_pred_probs_xg, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Cascade - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ens = BalanceCascade(classifier = 'adaboost', random_state = 1)\n",
    "X_train_res, Y_train_res = ens.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_probs_lr = np.zeros((20000,2))\n",
    "for idx in range(len(Y_train_res)): \n",
    "    clf_lr = LogisticRegression()\n",
    "    grid  = {'C' : 10.0 ** np.arange(-2,3),\n",
    "             'penalty' : ['l2','l1']}\n",
    "    cv = KFold(n_splits = 3, shuffle = True, random_state=0)\n",
    "    clf_lr_boost = GridSearchCV(clf_lr, grid, cv = cv)\n",
    "    clf_lr_boost.fit(X_train_res[idx], Y_train_res[idx])\n",
    "    y_pred_probs_lr += clf_lr_boost.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.84      0.91     19955\n",
      "          1       0.01      0.84      0.02        45\n",
      "\n",
      "avg / total       1.00      0.84      0.91     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, np.argmax(y_pred_probs_lr, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16767  3188]\n",
      " [    7    38]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, np.argmax(y_pred_probs_lr, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Cascade - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/631 [00:09<09:30,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "  3%|▎         | 21/631 [00:19<09:15,  1.10it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "  5%|▌         | 32/631 [00:29<09:09,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "  7%|▋         | 43/631 [00:39<08:58,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "  9%|▊         | 54/631 [00:49<08:52,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 10%|█         | 65/631 [00:59<08:40,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 12%|█▏        | 75/631 [01:09<08:33,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 14%|█▎        | 86/631 [01:19<08:22,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 16%|█▌        | 98/631 [01:29<08:07,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 19%|█▉        | 121/631 [01:49<07:41,  1.10it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 21%|██        | 133/631 [01:59<07:28,  1.11it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 23%|██▎       | 144/631 [02:09<07:17,  1.11it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 25%|██▍       | 156/631 [02:19<07:05,  1.12it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 27%|██▋       | 168/631 [02:30<06:53,  1.12it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 28%|██▊       | 179/631 [02:39<06:43,  1.12it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 30%|███       | 191/631 [02:49<06:31,  1.12it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 32%|███▏      | 202/631 [02:59<06:21,  1.13it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 34%|███▍      | 214/631 [03:09<06:10,  1.13it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 36%|███▌      | 225/631 [03:19<05:59,  1.13it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 37%|███▋      | 236/631 [03:29<05:50,  1.13it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 39%|███▉      | 247/631 [03:39<05:41,  1.12it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 41%|████      | 256/631 [03:49<05:36,  1.11it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 42%|████▏     | 264/631 [03:59<05:33,  1.10it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 44%|████▎     | 275/631 [04:10<05:24,  1.10it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 45%|████▌     | 284/631 [04:19<05:17,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 47%|████▋     | 294/631 [04:30<05:09,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 48%|████▊     | 303/631 [04:39<05:02,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 50%|████▉     | 315/631 [04:50<04:51,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 52%|█████▏    | 326/631 [04:59<04:40,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 54%|█████▎    | 338/631 [05:10<04:28,  1.09it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 55%|█████▍    | 345/631 [05:19<04:24,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 56%|█████▋    | 356/631 [05:29<04:14,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 58%|█████▊    | 367/631 [05:40<04:04,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 60%|█████▉    | 378/631 [05:49<03:54,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 61%|██████▏   | 388/631 [06:00<03:45,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 63%|██████▎   | 398/631 [06:09<03:36,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 65%|██████▍   | 409/631 [06:20<03:26,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 67%|██████▋   | 420/631 [06:30<03:16,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 68%|██████▊   | 430/631 [06:39<03:06,  1.08it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 70%|██████▉   | 440/631 [06:50<02:58,  1.07it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 71%|███████▏  | 450/631 [06:59<02:48,  1.07it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 73%|███████▎  | 460/631 [07:09<02:39,  1.07it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 74%|███████▍  | 470/631 [07:19<02:30,  1.07it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 76%|███████▌  | 480/631 [07:30<02:21,  1.07it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 77%|███████▋  | 489/631 [07:40<02:13,  1.06it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 79%|███████▉  | 497/631 [07:49<02:06,  1.06it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 80%|████████  | 505/631 [07:59<01:59,  1.05it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 81%|████████▏ | 513/631 [08:09<01:52,  1.05it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 83%|████████▎ | 522/631 [08:20<01:44,  1.04it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 84%|████████▍ | 532/631 [08:29<01:34,  1.04it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 86%|████████▌ | 543/631 [08:40<01:24,  1.04it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 88%|████████▊ | 553/631 [08:50<01:14,  1.04it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 89%|████████▉ | 561/631 [09:00<01:07,  1.04it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 90%|█████████ | 570/631 [09:10<00:58,  1.04it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 91%|█████████▏| 577/631 [09:19<00:52,  1.03it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 93%|█████████▎| 587/631 [09:30<00:42,  1.03it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 95%|█████████▍| 597/631 [09:40<00:33,  1.03it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 96%|█████████▌| 607/631 [09:50<00:23,  1.03it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      " 98%|█████████▊| 618/631 [10:00<00:12,  1.03it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|█████████▉| 628/631 [10:10<00:02,  1.03it/s]/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "100%|██████████| 631/631 [10:13<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs_rf = np.zeros((20000,2))\n",
    "for idx in tqdm(range(len(Y_train_res))):  \n",
    "    clf_base = RandomForestClassifier()\n",
    "    grid  = {'n_estimators' :[100],\n",
    "             'max_features' : ['auto'],\n",
    "             'criterion' : ['entropy']}\n",
    "   \n",
    "    clf_rf_boost = GridSearchCV(clf_base, grid)\n",
    "    clf_rf_boost.fit(X_train_res[idx], Y_train_res[idx])\n",
    "    y_pred_probs_rf += clf_rf_boost.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94     19955\n",
      "          1       0.02      0.89      0.03        45\n",
      "\n",
      "avg / total       1.00      0.89      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, np.argmax(y_pred_probs_rf, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17673  2282]\n",
      " [    5    40]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, np.argmax(y_pred_probs_rf, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Cascade - AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_probs_ada = np.zeros((20000,2))\n",
    "for idx in range(len(Y_train_res)): \n",
    "    clf_ada = AdaBoostClassifier()\n",
    "    clf_ada.fit(X_train_res[idx], Y_train_res[idx])\n",
    "    y_pred_probs_ada += clf_ada.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.88      0.94     19955\n",
      "          1       0.02      0.91      0.03        45\n",
      "\n",
      "avg / total       1.00      0.88      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, np.argmax(y_pred_probs_ada, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17621  2334]\n",
      " [    4    41]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, np.argmax(y_pred_probs_ada, axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Cascade - Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_probs_xg = np.zeros((20000,2))\n",
    "for idx in range(len(Y_train_res)): \n",
    "    clf_xgb = xgb.XGBClassifier()\n",
    "\n",
    "    clf_xgb.fit(X_train_res[idx], Y_train_res[idx])\n",
    "    y_pred_probs_xg += clf_xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95     19955\n",
      "          1       0.02      0.93      0.04        45\n",
      "\n",
      "avg / total       1.00      0.90      0.94     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, np.argmax(y_pred_probs_xg, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17890  2065]\n",
      " [    3    42]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, np.argmax(y_pred_probs_xg, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"xgboost_best.sav\"\n",
    "pickle.dump(clf_xgb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Predictions on True Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('dataset/test.csv', header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1873425.0</td>\n",
       "      <td>6011.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>871370.0</td>\n",
       "      <td>5816.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>299.67</td>\n",
       "      <td>68.39</td>\n",
       "      <td>68.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.39</td>\n",
       "      <td>294.68</td>\n",
       "      <td>68.39</td>\n",
       "      <td>68.39</td>\n",
       "      <td>68.39</td>\n",
       "      <td>68.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>963526.0</td>\n",
       "      <td>7512.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1458.82</td>\n",
       "      <td>99.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.55</td>\n",
       "      <td>99.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>140.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2063158.0</td>\n",
       "      <td>4899.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>449.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321137.0</td>\n",
       "      <td>7011.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1      2    3    4      5    6    7    8    9    ...    \\\n",
       "0  1873425.0  6011.0   16.0  0.0  0.0  978.0  0.0  2.0  1.0  0.0   ...     \n",
       "1   871370.0  5816.0  121.0  1.0  0.0  978.0  5.0  3.0  0.0  1.0   ...     \n",
       "2   963526.0  7512.0  152.0  0.0  0.0  578.0  0.0  2.0  1.0  1.0   ...     \n",
       "3  2063158.0  4899.0  151.0  1.0  0.0  978.0  6.0  3.0  0.0  1.0   ...     \n",
       "4   321137.0  7011.0  211.0  1.0  0.0  840.0  6.0  4.0  0.0  1.0   ...     \n",
       "\n",
       "        43     44     45   46     47      48     49     50     51      52  \n",
       "0   240.92   0.00   0.00  0.0   0.00    0.00   0.00   0.00   0.00    0.00  \n",
       "1   299.67  68.39  68.39  0.0  68.39  294.68  68.39  68.39  68.39   68.39  \n",
       "2  1458.82  99.55   0.00  0.0   0.00    0.00  99.55  99.55   0.00  140.40  \n",
       "3   449.29   0.00   0.00  0.0   0.00    0.00   0.00   0.00   0.00    0.00  \n",
       "4     0.00   0.00   0.00  0.0   0.00    0.00   0.00   0.00   0.00    0.00  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Drop columns as in previous case\n",
    "\n",
    "# Drop high variance column\n",
    "df_test.drop(0, axis = 1, inplace = True)\n",
    "\n",
    "# Drop highly correlated column \n",
    "df_test.drop(set(temp_ls), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/allwynjoseph/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "## prepare data for testing\n",
    "X_true_test = df_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get class and probability of class prediction\n",
    "Y_true_pred = np.zeros((100000,2))\n",
    "for idx in range(len(Y_train_res)): \n",
    "    clf_xgb = xgb.XGBClassifier()\n",
    "    clf_xgb.fit(X_train_res[idx], Y_train_res[idx])\n",
    "    Y_true_pred += clf_xgb.predict_proba(X_true_test)\n",
    "\n",
    "classes = np.argmax(Y_true_pred, axis = 1)\n",
    "probs = Y_true_pred.tolist()\n",
    "probs = [[round(probs[i][0]/631,3),round(probs[i][1]/631,3)] for i in range(len(probs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Write results into text file\n",
    "dataFile = open('prediction_test.txt', 'w')\n",
    "dataFile.write('Class'+'\\t' + 'Prob_0' + '\\t' + 'Prob_1' + '\\n')\n",
    "for i in range(len(probs)):\n",
    "    dataFile.write(str(classes[i])+'\\t' +str(probs[i][0])+'\\t' +str(probs[i][1])+'\\n')\n",
    "\n",
    "dataFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 52786, 1: 47214})"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Methods (discontinued as better results in terms of recall are bound to be achieved with hybrid boosting methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of class labels before resampling Counter({0: 79832, 1: 168})\n",
      "number of class labels after simple random resampling Counter({0: 79763, 1: 168})\n"
     ]
    }
   ],
   "source": [
    "######### TOMEK LINK REMOVAL #########\n",
    "\"\"\"\n",
    "Not too useful give that it removed a very few examples only\n",
    "\"\"\"\n",
    "us = TomekLinks(random_state= 1) \n",
    "X_train_tm, Y_train_tm = us.fit_sample(X_train, Y_train)\n",
    "print(\"number of class labels before resampling {}\".format(Counter(Y_train)))\n",
    "print(\"number of class labels after simple random resampling {}\".format(Counter(Y_train_tm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LOGISTIC\n",
    "clf_lr = LogisticRegression()\n",
    "grid = {'C': 10.0 ** np.arange(-2,3),# this is hyperparameter, C=1/lambda, where lambda is the regularisation term\n",
    "        'penalty': ['l1','l2']} # this would be the regularisation parameters\n",
    "    \n",
    "cv = KFold(n_splits = 5, shuffle= True, random_state = 0)\n",
    "clf = GridSearchCV(clf_lr, grid, cv=cv)\n",
    "clf.fit(X_train_tm,Y_train_tm)\n",
    "\n",
    "print(classification_report(Y_test, clf.predict(X_test)))\n",
    "print(confusion_matrix(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SVM\n",
    "clf_base = SVC()\n",
    "grid = {'kernel' : ['rbf', 'poly'],\n",
    "        'C' : [0.1, 1, 10],\n",
    "        'gamma' : [0.01, 0.1, 1],\n",
    "        'degree' : [1,3,6]}\n",
    "\n",
    "cv = KFold(n_splits = 3, shuffle = True, random_state = 0)\n",
    "clf = GridSearchCV(clf_base, grid)\n",
    "clf.fit(X_train_tm,y_train_tm)\n",
    "\n",
    "print(classification_report(Y_test, clf.predict(X_test)))\n",
    "print(confusion_matrix(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## RANDOM FOREST\n",
    "clf_base = RandomForestClassifier()\n",
    "grid  = {'n_estimators' :[500],\n",
    "         'max_features' : ['auto'],\n",
    "         'criterion' : ['entropy']}\n",
    "\n",
    "clf = GridSearchCV(clf_base, grid)\n",
    "clf.fit(X_train_tm,y_train_tm)\n",
    "\n",
    "print(classification_report(Y_test, clf.predict(X_test)))\n",
    "print(confusion_matrix(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ADABOOST\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train_tm,y_train_tm)\n",
    "\n",
    "print(classification_report(Y_test, clf.predict(X_test)))\n",
    "print(confusion_matrix(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
